{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93db0b6",
   "metadata": {},
   "source": [
    "Single Neuron w/ 3 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff727089",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "998e08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.2, 0.8, -0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34d06762",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d3d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = (inputs[0] * weights[0] +\n",
    "inputs[1] * weights[1] +\n",
    "inputs[2] * weights[2] + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8472566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8472756",
   "metadata": {},
   "source": [
    "Single Neuron w/ 4 inputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98380201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5];\n",
    "weights = [0.2, 0.8, -0.5, 1.0];\n",
    "bias = 2;\n",
    "output = (inputs[0] * weights[0] +\n",
    "inputs[1] * weights[1] +\n",
    "inputs[2] * weights[2] + \n",
    "inputs[3] * weights[3] + bias)\n",
    "print (output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d19b1",
   "metadata": {},
   "source": [
    "Layer of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c19282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5];\n",
    "\n",
    "weights1 = [0.2, 0.8, -0.5, 1.0];\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5];\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87];\n",
    "\n",
    "bias1 = 2;\n",
    "bias2 = 3;\n",
    "bias3 = 0.5;\n",
    "\n",
    "outputs = [\n",
    "    #Neruon 1:\n",
    "    inputs[0] * weights1[0] +\n",
    "    inputs[1] * weights1[1] +\n",
    "    inputs[2] * weights1[2] + \n",
    "    inputs[3] * weights1[3] + bias1,\n",
    "    #Neruon 2:\n",
    "    inputs[0] * weights2[0] +\n",
    "    inputs[1] * weights2[1] +\n",
    "    inputs[2] * weights2[2] + \n",
    "    inputs[3] * weights2[3] + bias2,\n",
    "    #Neruon 3:\n",
    "    inputs[0] * weights3[0] +\n",
    "    inputs[1] * weights3[1] +\n",
    "    inputs[2] * weights3[2] + \n",
    "    inputs[3] * weights3[3] + bias3];\n",
    "print (outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd53439c",
   "metadata": {},
   "source": [
    "Looping to scale code as thing can get challenging to code using this current method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0037461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5];\n",
    "weights = [[0.2, 0.8, -0.5, 1.0], \n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]];\n",
    "biases = [2, 3, 0.5];\n",
    "\n",
    "# Output of current layer\n",
    "layer_outputs = []\n",
    "# For each neruon\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    # Zeroed output of given neuron\n",
    "    neuron_output = 0\n",
    "    # For each input and weight to the neuron\n",
    "    for n_input,weight in zip(inputs,neuron_weights):\n",
    "        # Multiply this input by associated weight\n",
    "        # and add to the neuron's output variable\n",
    "        neuron_output += n_input * weight\n",
    "    # add bias\n",
    "    neuron_output += neuron_bias\n",
    "    # Put neuron's result to the layer's output list\n",
    "    layer_outputs.append(neuron_output)\n",
    "print (layer_outputs)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be5c63",
   "metadata": {},
   "source": [
    "This does the same thing as before, just in a more dynamic and scalable way. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df002a2d",
   "metadata": {},
   "source": [
    "Tensors, Arrays & Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8edc031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 5, 6, 2], [3, 2, 1, 3]], [[5, 2, 1, 2], [6, 4, 8, 4]], [[2, 8, 5, 3], [1, 1, 9, 4]]]\n"
     ]
    }
   ],
   "source": [
    "array = [[[1,5,6,2],\n",
    "         [3,2,1,3]],\n",
    "        [[5,2,1,2],\n",
    "         [6,4,8,4]],\n",
    "        [[2,8,5,3],\n",
    "         [1,1,9,4]]]\n",
    "#Array is a a shape of (3, 2, 4), or a 3D array. \n",
    "print (array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b94e5",
   "metadata": {},
   "source": [
    "A tensor object is an object that can be represented as an array. Are all tensors JUST arrays? No, but they are represented as arrays in our code so to us they are only arrays. \n",
    "\n",
    "A vector in math is what we call a list in python, or a 1-dimensional array in Numpy. \n",
    "\n",
    "Vector math in Python: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8454342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "\n",
    "#to obtain the dot product\n",
    "dot_product = a[0]* b[0] + a[1]* b[1] + a[2]* b[2]\n",
    "print (dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c857850",
   "metadata": {},
   "source": [
    "Now what if we called a \"inputs\" and b \"weights\"? Suddenly the dot product looks like a succint way to perform the operaitons we need and hgave arelay performed in plain python. Now we look to replicate in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5aed6289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = [1.0, 2.0, 3.0, 2.5];\n",
    "weights = [0.2, 0.8, -0.5, 1.0];\n",
    "bias = 2;\n",
    "\n",
    "output = np.dot(weights, inputs) + bias\n",
    "print (output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e690f",
   "metadata": {},
   "source": [
    "Calculating the output of a layer of 3 neurons in numpy via 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4814dad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = [1.0, 2.0, 3.0, 2.5];\n",
    "weights = [[0.2, 0.8, -0.5, 1.0], \n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]];\n",
    "biases = [2, 3, 0.5];\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "print (layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8b4de",
   "metadata": {},
   "source": [
    "To scale, nueral networks tend to recived data in batches. So far the input data has been one sample. This can be scaled into a batch of data, taking the 1d array of input into a 2d array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a155d73",
   "metadata": {},
   "source": [
    "This then takes the dot product that we have been using, and transformes it into a matrix product & we should also be aware of transpositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f77ed3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[[20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "print (np.dot(a,b))\n",
    "\n",
    "a = np.array([a])\n",
    "b = np.array([b]).T\n",
    "print (np.dot(a,b))\n",
    "#Same result of the dot product, but performed on matrices and returning a matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c35d65bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "#Full code up to this point\n",
    "\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]];\n",
    "weights = [[0.2, 0.8, -0.5, 1.0], \n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]];\n",
    "biases = [2, 3, 0.5];\n",
    "\n",
    "outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
